---
title: "Differential abundance analysis of AZM samples at baseline and week 48 using
  nine tools"
output:
  html_document:
    df_print: paged
  pdf_document: default
  author: Regina Esinam Abotsi, Department of Molecular and Cell Biology, University of Cape Town, South Africa
  
---


```{r, Packages, echo=FALSE}
library(tidyverse)
library(phyloseq); packageVersion("phyloseq") 
library(DESeq2); packageVersion("DESeq2")  
library(microbiome); packageVersion("microbiome") 
library(vegan); packageVersion("vegan") 
library(picante); packageVersion("picante")
library(ALDEx2); packageVersion("ALDEx2") 
library(metagenomeSeq); packageVersion("metagenomeSeq")  
library(dendextend); packageVersion("dendextend")
library(selbal); packageVersion("selbal") 
library(rms); packageVersion("rms")
library(breakaway); packageVersion("breakaway")  
library(VennDiagram); packageVersion("VennDiagram")  
library(DEFormats); packageVersion("DEFormats") 
library(apeglm); packageVersion("apeglm")   
library(corncob); packageVersion("corncob")  
library(ANCOMBC); packageVersion("ANCOMBC")  
library(Maaslin2); packageVersion("Maaslin2") 
library(edgeR); packageVersion("edgeR") 
library("cowplot")
library("devtools")
library(DESeq2)
library(apeglm)
library(ANCOMBC)
library(knitr)
library(eulerr)
library(ggplot2)
library(nlme)
library(compositions)
source("ancom_v2.1.R")

```


INTRODUCTION

In this analysis, I will conducted DA taxa analysis on AZM Baseline and Week 72 samples  

Differential abundance testing plan

1. Subsample to subset of interest

2. Merge taxa at Genus level

3. 0.5% prevalence filtering

4. Independently conduct the following analysis using the merged and filtered data and the tools listed below 


#Tools

1. Wilcoxon test (TSS) for unpaired samples
2. Wilcoxon test (CLR) for unpaired samples
3. Wilcoxon test (VST) for unpaired samples
4. DESeq2, 
5. ANCOM-BC, 
6. ALDEx2
7. Corncob
8. MaslinA
9. ANCOM-II




```{r}

#Create subsets for clr files
trial_CLR <- readRDS("breathe_sputum_phyloseq_trial_13Dec2021CLR.RDS") #created using the clr transformed data sent by Yao labelled "clr_trans_yx.csv

#Subsets of only AZM

AZM_CLR <-subset_samples(trial_CLR, trial_arm=="AZM")#441
AZM_CLR#441

#---AZM at Baseline and Week 72----
azm018_CLR<-subset_samples(AZM_CLR, visit!="Week 48")#318
azm018_CLR

#Selecting subset with samples at both Baseline and Week 72
azm018p_CLR<-subset_samples(azm018_CLR, visit018=="yes")#292
azm018p_CLR

# merge taxa to the Genus rank level

azm018pg_CLR<-tax_glom(azm018p_CLR, taxrank = rank_names(azm018p_CLR)[6])
taxa_names(azm018pg_CLR)<-as.character(tax_table(azm018pg_CLR)[,6])
OTU.azm018pg_CLR<-otu_table(azm018pg_CLR)
mean(OTU.azm018pg_CLR==0)
azm018pg_CLR



#Filtering
azm018p_CLR
azm018pg_CLR
azm018pfg_CLR <- filter_taxa(azm018pg_CLR, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
azm018pfg_CLR



```





```{r, Data import and subsetting}
# Read in phyloseq object
trial <- readRDS("breathe_sputum_phyloseq_trial_13Dec2021.RDS")

#Subsets of only AZM

AZM <-subset_samples(trial, trial_arm=="AZM")#441
AZM#441

#---AZM at Baseline and Week 72----
azm018<-subset_samples(AZM, visit!="Week 48")#318
azm018

#Selecting subset with samples at both Baseline and Week 72
azm018p<-subset_samples(azm018, visit018=="yes")#292
azm018p

# merge taxa to the Genus rank level

azm018pg<-tax_glom(azm018p, taxrank = rank_names(azm018p)[6])
taxa_names(azm018pg)<-as.character(tax_table(azm018pg)[,6])
OTU.azm018pg<-otu_table(azm018pg)
mean(OTU.azm018pg==0)
azm018pg



#Filtering
azm018p
azm018pg
azm018pfg <- filter_taxa(azm018pg, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
azm018pfg

```



### TSS Normalisation + WMW tests + BH FDR adjustment

```{r, TSS Normalisation + WMW tests + BH FDR adjustment}
azm018pfg.TSS<-transform_sample_counts(azm018pfg, function(x) { x/sum(x)})
OTU.TSSfg<-otu_table(azm018pfg.TSS)
group<-meta(azm018pfg)$visit

results.TSSfg.WMW<-data.frame(taxon=rownames(OTU.TSSfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.TSSfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.TSSfg[i,group=="Baseline"]),
                   y=as.numeric(OTU.TSSfg[i,group=="Week 72"]))
  results.TSSfg.WMW$stat[i]<-tmp$statistic
  results.TSSfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.TSSfg.WMW$p.adj<-p.adjust(results.TSSfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.TSSfg.WMW$p.adj<0.05, na.rm = TRUE)

#write all results to a csv file
write.csv(results.TSSfg.WMW, "res/results.TSSfg.WMW.csv")

#subset only significantly DA taxa and write to file
results.TSSfg.WMWsig<-results.TSSfg.WMW[which(results.TSSfg.WMW$p.adj<0.05),]
write.csv(results.TSSfg.WMWsig, "res/results.TSSfg.WMWsig.csv")
results.TSSfg.WMWsig
```
0  DA taxa were identified by this method


### VST Normalisation + WMW tests + BH FDR adjustment

```{r}
#covert the phyloseq object into Deseq so that VST normalisation can be conducted using the function in the Deseq package. 

azm018pfg.addcte<-transform_sample_counts(azm018pfg, function(x) {x+1})#this is important else you will get the error "Error in estimateSizeFactorsForMatrix(counts(object), locfunc = locfunc,  : every gene contains at least one zero, cannot compute log geometric means""

df<-phyloseq_to_deseq2(azm018pfg.addcte, ~ visit)
df2<-estimateSizeFactors(df)
df2<-estimateDispersions(df2)
df2<-getVarianceStabilizedData(df2)
OTU.vstfg<-otu_table(df2, taxa_are_rows = TRUE)

group<-meta(azm018pfg)$visit

results.vstfg.WMW<-data.frame(taxon=rownames(OTU.vstfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.vstfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.vstfg[i,group=="Baseline"]),
                   y=as.numeric(OTU.vstfg[i,group=="Week 72"]))
  results.vstfg.WMW$stat[i]<-tmp$statistic
  results.vstfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.vstfg.WMW$p.adj<-p.adjust(results.vstfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.vstfg.WMW$p.adj<0.05, na.rm = TRUE)



#write all results to a csv file
write.csv(results.vstfg.WMW, "res/results.vstfg.WMW.csv")

#subset only significantly DA taxa and write to file
results.vstfg.WMWsig<-results.vstfg.WMW[which(results.vstfg.WMW$p.adj<0.05),]
write.csv(results.vstfg.WMWsig, "res/results.vstfg.WMWsig.csv")
results.vstfg.WMWsig
```

 0 DA taxa were identified by this method



### CLR Transformation + WMW tests + BH FDR adjustment
data already clr transformed

```{r}

OTU.clrfg<-otu_table(azm018pfg_CLR)

group<-meta(azm018pfg_CLR)$visit

results.clrfg.WMW<-data.frame(taxon=rownames(OTU.clrfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.clrfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.clrfg[i,group=="Baseline"]),
                   y=as.numeric(OTU.clrfg[i,group=="Week 72"]))
  results.clrfg.WMW$stat[i]<-tmp$statistic
  results.clrfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.clrfg.WMW$p.adj<-p.adjust(results.clrfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.clrfg.WMW$p.adj<0.05, na.rm = TRUE)


#write all results to a csv file
write.csv(results.clrfg.WMW, "res/results.clrfgYao.WMW.csv")

#subset only significantly DA taxa and write to file
results.clrfg.WMWsig<-results.clrfg.WMW[which(results.clrfg.WMW$p.adj<0.05),]
write.csv(results.clrfg.WMWsig, "res/results.clrfg.WMWsigYao.csv")
results.clrfg.WMWsig
```
 0 DA taxa were identified by this method. 
 



## DESeq2

- DESeq2 is an R package originally developed for RNASeq data analysis

- is based on the NB distribution

- is very popular (easy to use) and implicitly makes use of the VST normalisation




#DESeq2 with apeglm


```{r}
dds <- phyloseq_to_deseq2(azm018pfg, ~ visit)      #convert to DESeq2 and DGEList objects
dds
dds1 <- DESeq(dds, test = "Wald", fitType = "local", sfType = "poscounts")
dds1

plotDispEsts(dds1)

res <- lfcShrink(dds1, coef=2, type="apeglm") 
```

```{r}
#plotMA(dds1)
```

```{r}
deseq_res_df <- data.frame(res) %>%
  rownames_to_column(var = "ASVs") %>%
  dplyr::arrange(padj)                                 

fdr_deseq <- deseq_res_df %>%
    dplyr::filter(padj < 0.05)

dim(fdr_deseq)
```
Deseq2 here detected 0 DA taxa 
```{r}
fdr_deseq
```


```{r}
ggplot(fdr_deseq, aes(x = ASVs, y = log2FoldChange, color = ASVs)) +
    geom_point(size = 4) +
    labs(y = "\nLog2 Fold-Change for Baseline vs. Week 72", x = "") +
    theme(axis.text.x = element_text(color = "black", size = 12),
          axis.text.y = element_text(color = "black", size = 12),
          axis.title.y = element_text(size = 14),
          axis.title.x = element_text(size = 14),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 12),
          legend.position = "none") +theme_bw()+
    coord_flip() +
    geom_hline(yintercept = 0, linetype="dotted")
```


```{r}
write.csv(fdr_deseq, "res/fdr_deseq.csv")

```


Deseq2 here detected 0 DA taxa 

## Methods specifically developed for compositional microbiome data

- ANCOM and ANCOM-BC 

- Aldex2 (very slow)



##ANCOM-BC
Lets see if we will get the same thing as above. The only difference here is the dataframe 

```{r}
ancom_da <- ancombc(phyloseq = azm018pfg, formula = "visit", 
              p_adj_method = "BH", zero_cut = 0.90, lib_cut = 1000, 
              group = "visit", struc_zero = TRUE, neg_lb = TRUE, tol = 1e-5, 
              max_iter = 100, conserve = TRUE, alpha = 0.05, global = FALSE)

ancom_res_df <- data.frame(
  Species = row.names(ancom_da$res$beta),
  beta = unlist(ancom_da$res$beta),
  se = unlist(ancom_da$res$se),
  W = unlist(ancom_da$res$W),
  p_val = unlist(ancom_da$res$p_val),
  q_val = unlist(ancom_da$res$q_val),
  diff_abn = unlist(ancom_da$res$diff_abn))

fdr_ancom <- ancom_res_df %>%
  dplyr::filter(q_val < 0.05)

dim(fdr_ancom)
```


This detected 0 DA taxa 
```{r}
head(fdr_ancom)
write.csv(fdr_ancom, "res/fdr_ancombc.csv")
```



### Aldex2

```{r}
#Run ALDEx2
aldex2_da <- ALDEx2::aldex(data.frame(phyloseq::otu_table(azm018pfg)), phyloseq::sample_data(azm018pfg)$visit, test="t", effect = TRUE, denom="iqlr")
```


```{r}
#Plot effect sizes
ALDEx2::aldex.plot(aldex2_da, type="MW", test="wilcox", called.cex = 1, cutoff = 0.05)
```

```{r}
#Adding taxonomic labels
taxa_info <- data.frame(tax_table(azm018pfg))
taxa_info <- taxa_info %>% rownames_to_column(var = "OTU")
```



```{r}
#Clean up presentation
sig_aldex2 <- aldex2_da %>%
  rownames_to_column(var = "OTU") %>%
  filter(wi.eBH < 0.05) %>%
  arrange(effect, wi.eBH) %>%
  dplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)
sig_aldex2 <- left_join(sig_aldex2, taxa_info)
```




```{r}
sig_aldex2
write.csv(sig_aldex2, "res/sig_aldex2.csv")
```

0  taxa detected by Aldex2



###Corncob

```{r}
corn_da <- differentialTest(formula = ~ visit,
                            phi.formula = ~ 1,
                            formula_null = ~ 1,
                            phi.formula_null = ~ 1,
                            data = azm018pfg,
                            test = "Wald", boot = FALSE,fdr="BH",
                            fdr_cutoff = 0.05)

fdr_corncob <- corn_da$significant_taxa
corn <- corn_da$p_fdr
dim(data.frame(fdr_corncob))
```

Corncob  detected 0 DA taxa 

```{r}
fdr_corncob
head(sort(corn_da$p_fdr))   
write.csv(corn, "res/corncob_p_fdr.csv")
write.csv(fdr_corncob, "res/fdr_corncob.csv")
```



###MaAsLin 2

Normalisation = TSS, transformation= LOG, fixed effects= visit
```{r}
mas1 <- Maaslin2(
  input_data = data.frame(otu_table(azm018pfg)),
  input_metadata = data.frame(sample_data(azm018pfg)),
  output = "./MaAsLin2_AZM018_random_effectsTSS_LOG",
  min_abundance = 0.0,
  min_prevalence = 0.0,
  normalization = "TSS",
  transform = "LOG",
  analysis_method = "LM",
  max_significance = 0.05,
  fixed_effects = "visit",
  correction = "BH",
  standardize = FALSE,
  cores = 1)
```

```{r}
mas1_res_df <- mas1$results

fdr_mas1 <- mas1_res_df %>%
    dplyr::filter(qval < 0.05)

dim(fdr_mas1)
```

0 DA found 
```{r}
fdr_mas1
write.csv(fdr_mas1, "MaAsLin2_AZM018_random_effectsTSS_LOG/fdr_mas1No_random_effects.csv")
```

Normalisation = CLR, transformation= NONE, fixed effects= visit
data already clr transformed hence normalisation option selected here is "NONE"
```{r}
mas3 <- Maaslin2(
  input_data = data.frame(otu_table(azm018pfg_CLR)),
  input_metadata = data.frame(sample_data(azm018pfg_CLR)),
  output = "./MaAsLin2_AZM018_random_effectsCLRYao_NONE",
  min_abundance = 0.0,
  min_prevalence = 0.0,
  normalization = "NONE",
  transform = "NONE",
  analysis_method = "LM",
  max_significance = 0.05,
  fixed_effects = "visit",
  correction = "BH",
  standardize = FALSE,
  cores = 1)
```

```{r}
mas3_res_df <- mas3$results

fdr_mas3 <- mas3_res_df %>%
    dplyr::filter(qval < 0.05)

dim(fdr_mas3)

fdr_mas3
write.csv(fdr_mas3, "./MaAsLin2_AZM018_random_effectsCLRYao_NONE/fdr_mas3_NONE_None_No_random_effectsYAOCLR.csv")
```


ANCOM-II
Link https://github.com/FrederickHuangLin/ANCOM



```{r, preparing for Data preprocessing for ANCOM-II}
#Preparing otu_data for feature_table for Data preprocessing step
otu_data = as.matrix(azm018pfg@otu_table)
otu_data<-as.data.frame(otu_data)

#Preparing meta_data  for Data preprocessing step
meta_data<-as.matrix(sample_data(azm018pfg))
meta_data<-as.data.frame(meta_data)
write.csv(meta_data, "res/meta_data_paired_azm072.csv")
#edit im excel so the sample ids have a column heading "SampleID). I have to find a way to do this in R
meta_data_new<-read.csv("res/meta_data_paired_azm072.csv")
```


```{r, Data preprocessing for ANCOM-II}
# Step 1: Data preprocessing

feature_table = otu_data; sample_var = "X"; group_var = "visit"
out_cut = 0.05; zero_cut = 0.90; lib_cut = 0; neg_lb = TRUE

prepro = feature_table_pre_process(feature_table, meta_data_new, sample_var, group_var, 
                                   out_cut, zero_cut, lib_cut, neg_lb)

feature_table = prepro$feature_table # Preprocessed feature table
meta_data = prepro$meta_data # Preprocessed metadata
struc_zero = prepro$structure_zeros # Structural zero info
```



```{r, ANCOM-II}
# Step 2: ANCOM

main_var = "visit"; p_adj_method = "BH"; alpha = 0.05
adj_formula = NULL; rand_formula = NULL
control = lmeControl(maxIter = 100, msMaxIter = 100, opt = "optim")
t_start = Sys.time()
res = ANCOM(feature_table, meta_data, struc_zero, main_var, p_adj_method, 
            alpha, adj_formula, rand_formula, control = control)
t_end = Sys.time()
t_run = t_end - t_start # around 2mins

res
write_csv(res$out, "res/res_azm072_paired.csv")
```



```{r}
ancom_res<-data.frame(res$out)
ancom_da<-ancom_res %>% 
  filter(detected_0.6==TRUE)
ancom_da$taxa_id #0
write.csv(ancom_da, "res/azm072.csv")

```



```{r, Plotting taxa}
# Step 3: Volcano Plot

# Number of taxa except structural zeros
n_taxa = ifelse(is.null(struc_zero), nrow(feature_table), sum(apply(struc_zero, 1, sum) == 0))
# Cutoff values for declaring differentially abundant taxa
cut_off = c(0.9 * (n_taxa -1), 0.8 * (n_taxa -1), 0.7 * (n_taxa -1), 0.6 * (n_taxa -1))
names(cut_off) = c("detected_0.9", "detected_0.8", "detected_0.7", "detected_0.6")

# Annotation data
dat_ann = data.frame(x = min(res$fig$data$x), y = cut_off["detected_0.7"], label = "W[0.7]")
```




```{r}
fig = res$fig + 
  geom_hline(yintercept = cut_off["detected_0.7"], linetype = "dashed") + 
  geom_text(data = dat_ann, aes(x = x, y = y, label = label), 
            size = 4, vjust = -0.5, hjust = 0, color = "orange", parse = TRUE)
fig 
```



```{r, Differentially abundant taxa detected by ANCOM-II}
ancom_res<-data.frame(res$out)
ancom_da<-ancom_res %>% 
  filter(detected_0.6==TRUE)
ancom_da$taxa_id #0
write.csv(ancom_da, "res/azm_072_paired.csv")
```














