---
title: Differential abundance analysis of AZM and Placebo samples at  12 months using
  nine tools
output:
  html_document:
    df_print: paged
  pdf_document: default
Author: Regina Esinam Abotsi, Department of Molecular and Cell Biology, University of Cape Town, South Africa.
---


```{r, Packages, echo=FALSE}
library(tidyverse)
library(phyloseq); packageVersion("phyloseq") 
library(DESeq2); packageVersion("DESeq2")  
library(microbiome); packageVersion("microbiome") 
library(vegan); packageVersion("vegan") 
library(picante); packageVersion("picante")
library(ALDEx2); packageVersion("ALDEx2") 
library(metagenomeSeq); packageVersion("metagenomeSeq")  
library(dendextend); packageVersion("dendextend")
library(selbal); packageVersion("selbal") 
library(rms); packageVersion("rms")
library(breakaway); packageVersion("breakaway")  
library(VennDiagram); packageVersion("VennDiagram")  
library(DEFormats); packageVersion("DEFormats") 
library(apeglm); packageVersion("apeglm")   
library(corncob); packageVersion("corncob")  
library(ANCOMBC); packageVersion("ANCOMBC")  
library(Maaslin2); packageVersion("Maaslin2") 
library(edgeR); packageVersion("edgeR") 
library("cowplot")
library("devtools")
library(DESeq2)
library(apeglm)
library(ANCOMBC)
library(knitr)
library(eulerr)
library(ggplot2)
library(nlme)
library(compositions)
source("ancom_v2.1_reg.R")

```


INTRODUCTION

In this analysis, I will conducted DA taxa analysis on AZM and Placebo samples  12 months per the following plan

Differential abundance testing plan

1. Subsample to subset of interest

2. Merge taxa at Genus level

3. 0.5% prevalence filtering

4. Independently conduct the following analysis using the merged and filtered data and the tools listed in the table below 

a. AZM and Placebo at baseline and 12 months (UNpaired test) -9 test


#Tools

1. Wilcoxon test (TSS) for unpaired samples
2. Wilcoxon test (CLR) for unpaired samples
3. Wilcoxon test (VST) for unpaired samples
4. DESeq2, 
5. ANCOM-BC, 
6. ALDEx2
7. Corncob
8. MaslinA
9. ANCOM-II




```{r}

#Create subsets for clr files
trial_CLR<- readRDS("breathe_sputum_phyloseq_trial_13Dec2021CLR.RDS") #created using the clr transformed data sent by Yao labelled "clr_trans_yx.csv

#Subsets of AZM and Placebo at each visit
t0_CLR <-subset_samples(trial_CLR, visit=="Baseline")#304
t0_CLR
t12_CLR <-subset_samples(trial_CLR, visit=="Week 48")#304
t12_CLR
t18_CLR <-subset_samples(trial_CLR, visit=="Week 72")#304
t18_CLR

# merge taxa to the Genus rank level

t0g_CLR<-tax_glom(t0_CLR, taxrank = rank_names(t0_CLR)[6])
taxa_names(t0g_CLR)<-as.character(tax_table(t0g_CLR)[,6])
OTU.t0g_CLR<-otu_table(t0g_CLR)
mean(OTU.t0g_CLR==0)
t0g_CLR


t12g_CLR<-tax_glom(t12_CLR, taxrank = rank_names(t12_CLR)[6])
taxa_names(t12g_CLR)<-as.character(tax_table(t12g_CLR)[,6])
OTU.t12g_CLR<-otu_table(t12g_CLR)
mean(OTU.t12g_CLR==0)
t12g_CLR


t18g_CLR<-tax_glom(t18_CLR, taxrank = rank_names(t18_CLR)[6])
taxa_names(t18g_CLR)<-as.character(tax_table(t18g_CLR)[,6])
OTU.t18g_CLR<-otu_table(t18g_CLR)
mean(OTU.t18g_CLR==0)
t18g_CLR


#Filtering
t0_CLR
t0g_CLR
t0fg_CLR <- filter_taxa(t0g_CLR, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
t0fg_CLR


t12_CLR
t12g_CLR
t12fg_CLR <- filter_taxa(t12g_CLR, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
t12fg_CLR

t18_CLR
t18g_CLR
t18fg_CLR <- filter_taxa(t18g_CLR, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
t18fg_CLR


```





```{r, Data import and subsetting}
# Read in phyloseq object
trial <- readRDS("breathe_sputum_phyloseq_trial_13Dec2021.RDS")

#Subsets of AZM and Placebo at 12m

t12 <-subset_samples(trial, visit=="Week 48")#304
t12

```


Lets check the sparseness of the data.

```{r, Sparseness check}
#check sparseness
OTU.t12<-otu_table(t12)
mean(OTU.t12==0)
```
Thus about 97 percent of the counts are equal to zero.

Now we go the to genus level because we want to work at this level. So merge and assign taxa names to the ASVs.


```{r,  Merging taxa at Genus level to deal with sparseness}
# merge taxa to the Genus rank level
t12g<-tax_glom(t12, taxrank = rank_names(t12)[6])
taxa_names(t12g)<-as.character(tax_table(t12g)[,6])
OTU.t12g<-otu_table(t12g)
mean(OTU.t12g==0)
t12g
```
Thus about 94 percent of the counts are equal to zero. Merging reduced taxa from 1665 to 444.

Lets check library sizes
```{r, Library sizes}
LibSizes<-sample_sums(t12g)
hist(LibSizes, xlab="Libary Size", main="Library sizes of AZM and Placebo samples from 48-week visit")
```

```{r}
summary(LibSizes)
```


The library sizes vary greatly from 1473 to 50,000. Solution to varying library sizes is normalisation. Methods include TSS, SCC, VST, RLE, TMM, CLR, ALR. So for the Wilcoxon test that I will use, I will use TSS, CLR and VST normalisations.


#Prevalence filtering


```{r, prevalence filtering}
#Filtering
t12
t12g
t12fg <- filter_taxa(t12g, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
t12fg


```

0.5% prevalence filtering reduced taxa from 444 to 170.
Going with 0.5% prevalence filtering


### TSS Normalisation + WMW tests + BH FDR adjustment

```{r, TSS Normalisation + WMW tests + BH FDR adjustment}
t12fg.TSS<-transform_sample_counts(t12fg, function(x) { x/sum(x)})
OTU.TSSfg<-otu_table(t12fg.TSS)
group<-meta(t12fg)$trial_arm

results.TSSfg.WMW<-data.frame(taxon=rownames(OTU.TSSfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.TSSfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.TSSfg[i,group=="AZM"]),
                   y=as.numeric(OTU.TSSfg[i,group=="Placebo"]))
  results.TSSfg.WMW$stat[i]<-tmp$statistic
  results.TSSfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.TSSfg.WMW$p.adj<-p.adjust(results.TSSfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.TSSfg.WMW$p.adj<0.05, na.rm = TRUE)

#write all results to a csv file
write.csv(results.TSSfg.WMW, "res/results.TSSfg.WMW.csv")

#subset only significantly DA taxa and write to file
results.TSSfg.WMWsig<-results.TSSfg.WMW[which(results.TSSfg.WMW$p.adj<0.05),]
write.csv(results.TSSfg.WMWsig, "res/results.TSSfg.WMWsig.csv")
results.TSSfg.WMWsig
```
32 DA taxa were identified by this method


### VST Normalisation + WMW tests + BH FDR adjustment

```{r}
#covert the phyloseq object into Deseq so that VST normalisation can be conducted using the function in the Deseq package. 

t12fg.addcte<-transform_sample_counts(t12fg, function(x) {x+1})#this is important else you will get the error "Error in estimateSizeFactorsForMatrix(counts(object), locfunc = locfunc,  : every gene contains at least one zero, cannot compute log geometric means""

df<-phyloseq_to_deseq2(t12fg.addcte, ~ trial_arm)
df2<-estimateSizeFactors(df)
df2<-estimateDispersions(df2)
df2<-getVarianceStabilizedData(df2)
OTU.vstfg<-otu_table(df2, taxa_are_rows = TRUE)

group<-meta(t12fg)$trial_arm

results.vstfg.WMW<-data.frame(taxon=rownames(OTU.vstfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.vstfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.vstfg[i,group=="AZM"]),
                   y=as.numeric(OTU.vstfg[i,group=="Placebo"]))
  results.vstfg.WMW$stat[i]<-tmp$statistic
  results.vstfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.vstfg.WMW$p.adj<-p.adjust(results.vstfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.vstfg.WMW$p.adj<0.05, na.rm = TRUE)



#write all results to a csv file
write.csv(results.vstfg.WMW, "res/results.vstfg.WMW.csv")

#subset only significantly DA taxa and write to file
results.vstfg.WMWsig<-results.vstfg.WMW[which(results.vstfg.WMW$p.adj<0.05),]
write.csv(results.vstfg.WMWsig, "res/results.vstfg.WMWsig.csv")
results.vstfg.WMWsig
```

22 DA taxa were identified by this method


### CLR Transformation + WMW tests + BH FDR adjustment

```{r}

OTU.clrfg<-otu_table(t12fg_CLR)

group<-meta(t12fg_CLR)$trial_arm

results.clrfg.WMW<-data.frame(taxon=rownames(OTU.clrfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.clrfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.clrfg[i,group=="AZM"]),
                   y=as.numeric(OTU.clrfg[i,group=="Placebo"]))
  results.clrfg.WMW$stat[i]<-tmp$statistic
  results.clrfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.clrfg.WMW$p.adj<-p.adjust(results.clrfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.clrfg.WMW$p.adj<0.05, na.rm = TRUE)


#write all results to a csv file
write.csv(results.clrfg.WMW, "res/results.clrfgYao.WMW.csv")

#subset only significantly DA taxa and write to file
results.clrfg.WMWsig<-results.clrfg.WMW[which(results.clrfg.WMW$p.adj<0.05),]
write.csv(results.clrfg.WMWsig, "res/results.clrfg.WMWsigYao.csv")
results.clrfg.WMWsig
```
22 DA taxa were identified by this method. Lets stick with Yao's data so that we can be consistent

```{r}
# extract OTU table
OTU<-otu_table(t12fg)
dim(OTU)
# extract taxa dat
TAX.table<-tax_table(t12fg)
TAXA<-rownames(TAX.table)
TAXA
head(TAX.table)
```



```{r, comparing all the classic test with different normalisation techniques}

taxa.TSSfg<-results.TSSfg.WMW$p.adj<0.05
taxa.TSSfg[is.na(taxa.TSSfg)]<-FALSE
taxa.TSSfg<-TAXA[taxa.TSSfg]

taxa.vstfg<-results.vstfg.WMW$p.adj<0.05
taxa.vstfg[is.na(taxa.vstfg)]<-FALSE
taxa.vstfg<-TAXA[taxa.vstfg]

taxa.clrfg<-results.clrfg.WMW$p.adj<0.05
taxa.clrfg[is.na(taxa.clrfg)]<-FALSE
taxa.clrfg<-TAXA[taxa.clrfg]

plot(venn(list(TSS=taxa.TSSfg,
               VST=taxa.vstfg,
               CLR=taxa.clrfg)),
     fills=c(TSS="lightcyan",VST="lightgreen", CLR="lightpink"))
```

```{r, Listing the taxa common to all the Wilcoxon methods regardless of normalisation}
Reduce(intersect, list(taxa.TSSfg, taxa.vstfg, taxa.clrfg)) 

```
22 taxa common to all the WILCOXON tests

```{r, Taxa picked up as DA by any method (Union)}
Reduce(unique, list(taxa.TSSfg, taxa.vstfg, taxa.clrfg)) 

```


#ESeq2 with apeglm

```{r}
dds <- phyloseq_to_deseq2(t12fg, ~ trial_arm)      #convert to DESeq2 and DGEList objects
dds
dds1 <- DESeq(dds, test = "Wald", fitType = "local", sfType = "poscounts")
dds1
```

```{r}
plotDispEsts(dds1)
```

```{r}
res <- lfcShrink(dds1, coef=2, type="apeglm") 
```

```{r}
#plotMA(dds1)
```

```{r}
deseq2_res_df <- data.frame(res) %>%
  rownames_to_column(var = "ASVs")

dim(deseq2_res_df)
```


```{r}
deseq_res_df <- data.frame(res) %>%
  rownames_to_column(var = "ASVs") %>%
  dplyr::arrange(padj)                                 

fdr_deseq <- deseq_res_df %>%
    dplyr::filter(padj < 0.05)

dim(fdr_deseq)
```
Deseq2 here detected 11 DA taxa 
```{r}
fdr_deseq
```


```{r}
ggplot(fdr_deseq, aes(x = ASVs, y = log2FoldChange, color = ASVs)) +
    geom_point(size = 4) +
    labs(y = "\nLog2 Fold-Change for AZM vs. Placebo", x = "") +
    theme(axis.text.x = element_text(color = "black", size = 12),
          axis.text.y = element_text(color = "black", size = 12),
          axis.title.y = element_text(size = 14),
          axis.title.x = element_text(size = 14),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 12),
          legend.position = "none") + theme_bw()+
    coord_flip() +
    geom_hline(yintercept = 0, linetype="dotted")
```


```{r}
write.csv(fdr_deseq, "res/fdr_deseq.csv")
write.csv(deseq2_res_df, "res/deseq2_results.csv")
```




## Methods specifically developed for compositional microbiome data

- ANCOM and ANCOM-BC 

- Aldex2 (very slow)


##ANCOM-BC


```{r}
ancom_da <- ancombc(phyloseq = t12fg, formula = "trial_arm", 
              p_adj_method = "BH", zero_cut = 0.90, lib_cut = 1000, 
              group = "trial_arm", struc_zero = TRUE, neg_lb = TRUE, tol = 1e-5, 
              max_iter = 100, conserve = TRUE, alpha = 0.05, global = FALSE)

ancom_res_df <- data.frame(
  Species = row.names(ancom_da$res$beta),
  beta = unlist(ancom_da$res$beta),
  se = unlist(ancom_da$res$se),
  W = unlist(ancom_da$res$W),
  p_val = unlist(ancom_da$res$p_val),
  q_val = unlist(ancom_da$res$q_val),
  diff_abn = unlist(ancom_da$res$diff_abn))

dim(ancom_res_df) 

fdr_ancom <- ancom_res_df %>%
  dplyr::filter(q_val < 0.05)

dim(fdr_ancom)


```


This detected 12 DA taxa 
```{r}
head(fdr_ancom)
write.csv(fdr_ancom, "res/fdr_ancombc.csv")
write.csv(ancom_res_df, "res/ancombc_results.csv")
```



### Aldex2

```{r}
#Run ALDEx2
aldex2_da <- ALDEx2::aldex(data.frame(phyloseq::otu_table(t12fg)), phyloseq::sample_data(t12fg)$trial_arm, test="t", effect = TRUE, denom="iqlr")
```


```{r}
#Plot effect sizes
ALDEx2::aldex.plot(aldex2_da, type="MW", test="wilcox", called.cex = 1, cutoff = 0.05)
```

```{r}
#Adding taxonomic labels
taxa_info <- data.frame(tax_table(t12fg))
taxa_info <- taxa_info %>% rownames_to_column(var = "OTU")
```



```{r}
#Clean up presentation
sig_aldex2 <- aldex2_da %>%
  rownames_to_column(var = "OTU") %>%
  filter(wi.eBH < 0.05) %>%
  arrange(effect, wi.eBH) %>%
  dplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)
sig_aldex2 <- left_join(sig_aldex2, taxa_info)
```
#Export all results
```{r}
#Clean up presentation
aldex2_results <- aldex2_da %>%
  rownames_to_column(var = "OTU")
  #filter(wi.eBH < 0.05) %>%
  #arrange(effect, wi.eBH) %>%
  #dplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)
aldex2_result2 <- left_join(aldex2_results, taxa_info)
```



```{r}
sig_aldex2
write.csv(sig_aldex2, "res/sig_aldex2.csv")
write.csv(aldex2_result2, "res/aldex2results.csv")
```

15(6) taxa detected by Aldex2


###Corncob

```{r}
corn_da <- differentialTest(formula = ~ trial_arm,
                            phi.formula = ~ 1,
                            formula_null = ~ 1,
                            phi.formula_null = ~ 1,
                            data = t12fg,
                            test = "Wald", boot = FALSE,fdr="BH",
                            fdr_cutoff = 0.05)

fdr_corncob <- corn_da$significant_taxa
corn <- corn_da$p_fdr
dim(data.frame(fdr_corncob))
```

```{r}
plot(corn_da, total = TRUE, color = "trial_arm", B = 170)
```




Corncob  detected 26 DA taxa 

```{r}
fdr_corncob
head(sort(corn_da$p_fdr))   
write.csv(corn, "res/corncob_p_fdr.csv")
write.csv(fdr_corncob, "res/fdr_corncob.csv")
write.csv(corn_da$p_fdr, "res/corncob-results.csv")
```

#Write a code to pull estimate values for all models of each OTU else I will have to do it manually

```{r}
corndf<-as.matrix(corn_da[["all_models"]])


#write.table( data.frame(corndf[[1]][["coefficients"]]), 'corncob_estimates0511020.csv'  , append= T, sep=',' )

#write.table( data.frame(corndf[[2]][["coefficients"]]), 'corncob_estimates0511020.csv'  , append= T, sep=',' )

for (i in 1:170) {
  write.table( data.frame(corndf[[i]][["coefficients"]]), 'res/corncob_estimates17Dec2021.csv'  , append= T, sep=',' )
}

#check and ensure coeffcients are correct. Use padjust from "corncob-results.csv"
corndf[[1]][["coefficients"]]
corndf[[90]][["coefficients"]]
corndf[[168]][["coefficients"]]
```


###MaAsLin 2

Normalisation = TSS, transformation= LOG, fixed effects= trial_arm
```{r}
mas1 <- Maaslin2(
  input_data = data.frame(otu_table(t12fg)),
  input_metadata = data.frame(sample_data(t12fg)),
  output = "./MaAsLin2TSS_Log_trial_arm",
  min_abundance = 0.0,
  min_prevalence = 0.0,
  normalization = "TSS",
  transform = "LOG",
  analysis_method = "LM",
  max_significance = 0.05,
  fixed_effects = "trial_arm",
  correction = "BH",
  standardize = FALSE,
  cores = 1)
```

```{r}
mas1_res_df <- mas1$results

fdr_mas1 <- mas1_res_df %>%
    dplyr::filter(qval < 0.05)

dim(fdr_mas1)
```

33 DA found 
```{r}
fdr_mas1
write.csv(fdr_mas1, "./MaAsLin2TSS_Log_trial_arm/fdr_mas1No_random_effects.csv")
write.csv(mas1_res_df, "./MaAsLin2TSS_Log_trial_arm/mas1TSSNo_random_effects.csv")
```

Normalisation = CLR, transformation= NONE, fixed effects= trial_arm
CLR was already applied to the data hence normalisation option selected is "NONE"
```{r}
mas3 <- Maaslin2(
  input_data = data.frame(otu_table(t12fg_CLR)),
  input_metadata = data.frame(sample_data(t12fg_CLR)),
  output = "./MaAsLin2YAO_None_trial_arm",
  min_abundance = 0.0,
  min_prevalence = 0.0,
  normalization = "NONE",
  transform = "NONE",
  analysis_method = "LM",
  max_significance = 0.05,
  fixed_effects = "trial_arm",
  correction = "BH",
  standardize = FALSE,
  cores = 1)
```

```{r}
mas3_res_df <- mas3$results

fdr_mas3 <- mas3_res_df %>%
    dplyr::filter(qval < 0.05)

dim(fdr_mas3)

fdr_mas3
write.csv(fdr_mas3, "./MaAsLin2YAO_None_trial_arm/fdr_mas3_NONE_None_No_random_effectsYAOCLR.csv")
write.csv(mas3_res_df, "./MaAsLin2YAO_None_trial_arm/mas3CLRYAONo_random_effects.csv")
```


##Assessing overlap across approaches of MaAslin2


```{r}
Reduce(intersect, list(fdr_mas1$feature,fdr_mas2$feature ))   
```
Assessing the union taxa from all the MaAslin2 method
```{r}
Reduce(unique, list(fdr_mas1$feature,fdr_mas2$feature ))   
```

```{r}
da_venn <- venn.diagram(
  x = list(fdr_mas1$feature,fdr_mas2$feature),
  category.names = c("TSS_LOG_noRandom" , "CLR_NONE_noRandom"),
  filename = NULL,
  fill = c("#8DD3C7", "#FFFFB3"),
  margin = 0.1)

grid::grid.newpage()
grid::grid.draw(da_venn)   
```




ANCOM-II
Link https://github.com/FrederickHuangLin/ANCOM

```{r, preparing for Data preprocessing for ANCOM-II}
#Preparing otu_data for feature_table for Data preprocessing step
otu_data = as.matrix(t12fg@otu_table)
otu_data<-as.data.frame(otu_data)

#Preparing meta_data  for Data preprocessing step
meta_data<-as.matrix(sample_data(t12fg))
meta_data<-as.data.frame(meta_data)
write.csv(meta_data, "res/meta_data_paired_trial12mm.csv")
#edit im excel so the sample ids have a column heading "SampleID). I have to find a way to do this in R
meta_data_new<-read.csv("res/meta_data_paired_trial12mm.csv")
```


```{r, Data preprocessing for ANCOM-II}
# Step 1: Data preprocessing

feature_table = otu_data; sample_var = "X"; group_var = "trial_arm"
out_cut = 0.05; zero_cut = 0.90; lib_cut = 0; neg_lb = TRUE

prepro = feature_table_pre_process(feature_table, meta_data_new, sample_var, group_var, 
                                   out_cut, zero_cut, lib_cut, neg_lb)

feature_table = prepro$feature_table # Preprocessed feature table
meta_data = prepro$meta_data # Preprocessed metadata
struc_zero = prepro$structure_zeros # Structural zero info
```



```{r, ANCOM-II}
# Step 2: ANCOM

main_var = "trial_arm"; p_adj_method = "BH"; alpha = 0.05
adj_formula = NULL; rand_formula = NULL
control = lmeControl(maxIter = 100, msMaxIter = 100, opt = "optim")
t_start = Sys.time()
res = ANCOM(feature_table, meta_data, struc_zero, main_var, p_adj_method, 
            alpha, adj_formula, rand_formula, control = control)
t_end = Sys.time()
t_run = t_end - t_start # around 2mins

res
write_csv(res$out, "res/res_trial12mm_paired.csv")
```



```{r}
ancom_res<-data.frame(res$out)
ancom_da<-ancom_res %>% 
  filter(detected_0.6==TRUE)
ancom_da$taxa_id #0
write.csv(ancom_da, "res/datrial12m.csv")

```



```{r, Plotting taxa}
# Step 3: Volcano Plot

# Number of taxa except structural zeros
n_taxa = ifelse(is.null(struc_zero), nrow(feature_table), sum(apply(struc_zero, 1, sum) == 0))
# Cutoff values for declaring differentially abundant taxa
cut_off = c(0.9 * (n_taxa -1), 0.8 * (n_taxa -1), 0.7 * (n_taxa -1), 0.6 * (n_taxa -1))
names(cut_off) = c("detected_0.9", "detected_0.8", "detected_0.7", "detected_0.6")

# Annotation data
dat_ann = data.frame(x = min(res$fig$data$x), y = cut_off["detected_0.7"], label = "W[0.7]")
```




```{r}
fig = res$fig + 
  geom_hline(yintercept = cut_off["detected_0.7"], linetype = "dashed") + 
  geom_text(data = dat_ann, aes(x = x, y = y, label = label), 
            size = 4, vjust = -0.5, hjust = 0, color = "orange", parse = TRUE)
fig 
```



```{r, Differentially abundant taxa detected by ANCOM-II}
ancom_res<-data.frame(res$out)
ancom_da<-ancom_res %>% 
  filter(detected_0.6==TRUE)
ancom_da$taxa_id #0
write.csv(ancom_da, "res/datrial12m_allvisitspaired.csv")
```



```{r, Common to all ten methods}
Reduce(intersect, list( fdr_deseq$ASVs, fdr_corncob, fdr_mas1$feature,fdr_mas2$feature, fdr_ancom$Species, results.clrfg.WMWsig$taxon, results.TSSfg.WMWsig$taxon, results.vstfg.WMWsig$taxon, sig_aldex2$OTU, ancom_da$taxa_id))  
```

