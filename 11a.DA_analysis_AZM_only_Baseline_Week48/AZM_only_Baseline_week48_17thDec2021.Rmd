---
title: "Differential abundance analysis of AZM samples at baseline and week 48 using
  nine tools"
output:
  html_document:
    df_print: paged
  pdf_document: default
  author: Regina Esinam Abotsi, Department of Moclecular and Cell Biology, University of Cape Town, South Africa
---


```{r, Packages, echo=FALSE}
library(tidyverse)
library(phyloseq); packageVersion("phyloseq") 
library(DESeq2); packageVersion("DESeq2")  
library(microbiome); packageVersion("microbiome") 
library(vegan); packageVersion("vegan") 
library(picante); packageVersion("picante")
library(ALDEx2); packageVersion("ALDEx2") 
library(metagenomeSeq); packageVersion("metagenomeSeq")  
library(dendextend); packageVersion("dendextend")
library(selbal); packageVersion("selbal") 
library(rms); packageVersion("rms")
library(breakaway); packageVersion("breakaway")  
library(VennDiagram); packageVersion("VennDiagram")  
library(DEFormats); packageVersion("DEFormats") 
library(apeglm); packageVersion("apeglm")   
library(corncob); packageVersion("corncob")  
library(ANCOMBC); packageVersion("ANCOMBC")  
library(Maaslin2); packageVersion("Maaslin2") 
library(edgeR); packageVersion("edgeR") 
library("cowplot")
library("devtools")
library(DESeq2)
library(apeglm)
library(ANCOMBC)
library(knitr)
library(eulerr)
library(ggplot2)
library(nlme)
library(compositions)
source("ancom_v2.1.R")

```


INTRODUCTION

In this analysis, I will conducted DA taxa analysis on AZM and Week 48 samples per the following plan

Differential abundance testing plan

1. Subsample to subset of interest

2. Merge taxa at Genus level

3. 0.5% prevalence filtering

4. Independently conduct the following analysis using the merged and filtered data and the tools listed  below 

#Tools

1. Wilcoxon test (TSS) for unpaired samples
2. Wilcoxon test (CLR) for unpaired samples
3. Wilcoxon test (VST) for unpaired samples
4. DESeq2, 
5. ANCOM-BC, 
6. ALDEx2
7. Corncob
8. MaslinA
9. ANCOM-II




```{r}

#Create subsets for clr files
trial_CLR <- readRDS("breathe_sputum_phyloseq_trial_13Dec2021CLR.RDS") #created using the clr transformed data sent by Yao labelled "clr_trans_yx.csv

#Subsets of only AZM

AZM_CLR <-subset_samples(trial_CLR, trial_arm=="AZM")#441
AZM_CLR#441

#---AZM at Baseline and Week 48----
azm012_CLR<-subset_samples(AZM_CLR, visit!="Week 72")#318
azm012_CLR

#Selecting subset with samples at both Baseline and Week 48
azm012p_CLR<-subset_samples(azm012_CLR, visit012=="yes")#292
azm012p_CLR

# merge taxa to the Genus rank level

azm012pg_CLR<-tax_glom(azm012p_CLR, taxrank = rank_names(azm012p_CLR)[6])
taxa_names(azm012pg_CLR)<-as.character(tax_table(azm012pg_CLR)[,6])
OTU.azm012pg_CLR<-otu_table(azm012pg_CLR)
mean(OTU.azm012pg_CLR==0)
azm012pg_CLR



#Filtering
azm012p_CLR
azm012pg_CLR
azm012pfg_CLR <- filter_taxa(azm012pg_CLR, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
azm012pfg_CLR



```





```{r, Data import and subsetting}
# Read in phyloseq object
trial <- readRDS("breathe_sputum_phyloseq_trial_13Dec2021.RDS")

#Subsets of only AZM

AZM <-subset_samples(trial, trial_arm=="AZM")#441
AZM#441

#---AZM at Baseline and Week 48----
azm012<-subset_samples(AZM, visit!="Week 72")#318
azm012

#Selecting subset with samples at both Baseline and Week 48
azm012p<-subset_samples(azm012, visit012=="yes")#292
azm012p

# merge taxa to the Genus rank level

azm012pg<-tax_glom(azm012p, taxrank = rank_names(azm012p)[6])
taxa_names(azm012pg)<-as.character(tax_table(azm012pg)[,6])
OTU.azm012pg<-otu_table(azm012pg)
mean(OTU.azm012pg==0)
azm012pg



#Filtering
azm012p
azm012pg
azm012pfg <- filter_taxa(azm012pg, function(x) sum(x > 0) > (0.005*length(x)), TRUE)   #removing species not seen > 1/2% of samples
azm012pfg

```



### TSS Normalisation + WMW tests + BH FDR adjustment

```{r, TSS Normalisation + WMW tests + BH FDR adjustment}
azm012pfg.TSS<-transform_sample_counts(azm012pfg, function(x) { x/sum(x)})
OTU.TSSfg<-otu_table(azm012pfg.TSS)
group<-meta(azm012pfg)$visit

results.TSSfg.WMW<-data.frame(taxon=rownames(OTU.TSSfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.TSSfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.TSSfg[i,group=="Baseline"]),
                   y=as.numeric(OTU.TSSfg[i,group=="Week 48"]))
  results.TSSfg.WMW$stat[i]<-tmp$statistic
  results.TSSfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.TSSfg.WMW$p.adj<-p.adjust(results.TSSfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.TSSfg.WMW$p.adj<0.05, na.rm = TRUE)

#write all results to a csv file
write.csv(results.TSSfg.WMW, "res/results.TSSfg.WMW.csv")

#subset only significantly DA taxa and write to file
results.TSSfg.WMWsig<-results.TSSfg.WMW[which(results.TSSfg.WMW$p.adj<0.05),]
write.csv(results.TSSfg.WMWsig, "res/results.TSSfg.WMWsig.csv")
results.TSSfg.WMWsig
```
27 DA taxa were identified by this method


### VST Normalisation + WMW tests + BH FDR adjustment

```{r}
#covert the phyloseq object into Deseq so that VST normalisation can be conducted using the function in the Deseq package. 

azm012pfg.addcte<-transform_sample_counts(azm012pfg, function(x) {x+1})#this is important else you will get the error "Error in estimateSizeFactorsForMatrix(counts(object), locfunc = locfunc,  : every gene contains at least one zero, cannot compute log geometric means""

df<-phyloseq_to_deseq2(azm012pfg.addcte, ~ visit)
df2<-estimateSizeFactors(df)
df2<-estimateDispersions(df2)
df2<-getVarianceStabilizedData(df2)
OTU.vstfg<-otu_table(df2, taxa_are_rows = TRUE)

group<-meta(azm012pfg)$visit

results.vstfg.WMW<-data.frame(taxon=rownames(OTU.vstfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.vstfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.vstfg[i,group=="Baseline"]),
                   y=as.numeric(OTU.vstfg[i,group=="Week 48"]))
  results.vstfg.WMW$stat[i]<-tmp$statistic
  results.vstfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.vstfg.WMW$p.adj<-p.adjust(results.vstfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.vstfg.WMW$p.adj<0.05, na.rm = TRUE)



#write all results to a csv file
write.csv(results.vstfg.WMW, "res/results.vstfg.WMW.csv")

#subset only significantly DA taxa and write to file
results.vstfg.WMWsig<-results.vstfg.WMW[which(results.vstfg.WMW$p.adj<0.05),]
write.csv(results.vstfg.WMWsig, "res/results.vstfg.WMWsig.csv")
results.vstfg.WMWsig
```

17 DA taxa were identified by this method



### CLR Transformation + WMW tests + BH FDR adjustment
data already clr transformed

```{r}

OTU.clrfg<-otu_table(azm012pfg_CLR)

group<-meta(azm012pfg_CLR)$visit

results.clrfg.WMW<-data.frame(taxon=rownames(OTU.clrfg),stat=NA,p=NA)

for(i in 1:nrow(OTU.clrfg)) {
  tmp<-wilcox.test(x=as.numeric(OTU.clrfg[i,group=="Baseline"]),
                   y=as.numeric(OTU.clrfg[i,group=="Week 48"]))
  results.clrfg.WMW$stat[i]<-tmp$statistic
  results.clrfg.WMW$p[i]<-tmp$p.value
}

#correction for multiple testing using BH
results.clrfg.WMW$p.adj<-p.adjust(results.clrfg.WMW$p, method="BH")

#How many taxa are DA after correcting for multiple testing
sum(results.clrfg.WMW$p.adj<0.05, na.rm = TRUE)


#write all results to a csv file
write.csv(results.clrfg.WMW, "res/results.clrfgYao.WMW.csv")

#subset only significantly DA taxa and write to file
results.clrfg.WMWsig<-results.clrfg.WMW[which(results.clrfg.WMW$p.adj<0.05),]
write.csv(results.clrfg.WMWsig, "res/results.clrfg.WMWsigYao.csv")
results.clrfg.WMWsig
```
16 DA taxa were identified by this method. Lets stick with Yao's data so that we can be consistent

```{r}
# extract OTU table
OTU<-otu_table(azm012pfg)
dim(OTU)
# extract taxa dat
TAX.table<-tax_table(azm012pfg)
TAXA<-rownames(TAX.table)
TAXA
head(TAX.table)
```



```{r, comparing all the classic test with different normalisation techniques}

taxa.TSSfg<-results.TSSfg.WMW$p.adj<0.05
taxa.TSSfg[is.na(taxa.TSSfg)]<-FALSE
taxa.TSSfg<-TAXA[taxa.TSSfg]

taxa.vstfg<-results.vstfg.WMW$p.adj<0.05
taxa.vstfg[is.na(taxa.vstfg)]<-FALSE
taxa.vstfg<-TAXA[taxa.vstfg]

taxa.clrfg<-results.clrfg.WMW$p.adj<0.05
taxa.clrfg[is.na(taxa.clrfg)]<-FALSE
taxa.clrfg<-TAXA[taxa.clrfg]

plot(venn(list(TSS=taxa.TSSfg,
               VST=taxa.vstfg,
               CLR=taxa.clrfg)),
     fills=c(TSS="lightcyan",VST="lightgreen", CLR="lightpink"))
```

```{r, Listing the taxa common to all the Wilcoxon methods regardless of normalisation}
Reduce(intersect, list(taxa.TSSfg, taxa.vstfg, taxa.clrfg)) 

```
12 taxa common to all the WILCOXON tests

```{r, Taxa picked up as DA by any method (Union)}

Reduce(unique, list(taxa.TSSfg, taxa.vstfg, taxa.clrfg)) 

```



## DESeq2

- DESeq2 is an R package originally developed for RNASeq data analysis

- is based on the NB distribution

- is very popular (easy to use) and implicitly makes use of the VST normalisation



#DESeq2 with apeglm

I think this is the option to use
```{r}
dds <- phyloseq_to_deseq2(azm012pfg, ~ visit)      #convert to DESeq2 and DGEList objects
dds
dds1 <- DESeq(dds, test = "Wald", fitType = "local", sfType = "poscounts")
dds1
```

```{r}
plotDispEsts(dds1)
```

```{r}
res <- lfcShrink(dds1, coef=2, type="apeglm") 
```

```{r}
#plotMA(dds1)
```

```{r}
deseq_res_df <- data.frame(res) %>%
  rownames_to_column(var = "ASVs") %>%
  dplyr::arrange(padj)                                 

fdr_deseq <- deseq_res_df %>%
    dplyr::filter(padj < 0.05)

dim(fdr_deseq)
```
Deseq2 here detected 13 DA taxa 
```{r}
fdr_deseq
```


```{r}
ggplot(fdr_deseq, aes(x = ASVs, y = log2FoldChange, color = ASVs)) +
    geom_point(size = 4) +
    labs(y = "\nLog2 Fold-Change for Baseline vs. Week 48", x = "") +
    theme(axis.text.x = element_text(color = "black", size = 12),
          axis.text.y = element_text(color = "black", size = 12),
          axis.title.y = element_text(size = 14),
          axis.title.x = element_text(size = 14),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 12),
          legend.position = "none") +theme_bw()+
    coord_flip() +
    geom_hline(yintercept = 0, linetype="dotted")
```
```{r}
deseq3_res_df <- data.frame(res) %>%
  rownames_to_column(var = "ASVs")
```


```{r}
write.csv(fdr_deseq, "res/fdr_deseq.csv")
write.csv(deseq3_res_df, "res/deseq3_AZM048_results.csv")
```


## Methods specifically developed for compositional microbiome data

- ANCOM and ANCOM-BC 

- Aldex2 (very slow)



```{r, Listing the taxa common to all the Wilcoxon methods regardless of normalisation, Deseq2, ancombc}
Reduce(intersect, list(taxa.vstfg, taxa.clrfg, fdr_deseq$ASVs)) 
```


##ANCOM-BC


```{r}
ancom_da1 <- ancombc(phyloseq = azm012pfg, formula = "visit", 
              p_adj_method = "BH", zero_cut = 0.90, lib_cut = 1000, 
              group = "visit", struc_zero = TRUE, neg_lb = TRUE, tol = 1e-5, 
              max_iter = 100, conserve = TRUE, alpha = 0.05, global = FALSE)

ancom_res_df1 <- data.frame(
  Species = row.names(ancom_da1$res$beta),
  beta = unlist(ancom_da1$res$beta),
  se = unlist(ancom_da1$res$se),
  W = unlist(ancom_da1$res$W),
  p_val = unlist(ancom_da1$res$p_val),
  q_val = unlist(ancom_da1$res$q_val),
  diff_abn = unlist(ancom_da1$res$diff_abn))
dim(ancom_res_df1)
fdr_ancom1 <- ancom_res_df1 %>%
  dplyr::filter(q_val < 0.05)

dim(fdr_ancom1)
```


This detected 16 DA taxa
```{r}
head(fdr_ancom1)
fdr_ancom1
write.csv(fdr_ancom1, "res/fdr_ancombc.csv")
write.csv(ancom_res_df1, "res/ancombc_resultsAZM012m.csv")
```



### Aldex2

```{r}
#Run ALDEx2
aldex2_da <- ALDEx2::aldex(data.frame(phyloseq::otu_table(azm012pfg)), phyloseq::sample_data(azm012pfg)$visit, test="t", effect = TRUE, denom="iqlr")
```


```{r}
#Plot effect sizes
ALDEx2::aldex.plot(aldex2_da, type="MW", test="wilcox", called.cex = 1, cutoff = 0.05)
```

```{r}
#Adding taxonomic labels
taxa_info <- data.frame(tax_table(azm012pfg))
taxa_info <- taxa_info %>% rownames_to_column(var = "OTU")
```



```{r}
#Clean up presentation
sig_aldex2 <- aldex2_da %>%
  rownames_to_column(var = "OTU") %>%
  filter(wi.eBH < 0.05) %>%
  arrange(effect, wi.eBH) %>%
  dplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)
sig_aldex2 <- left_join(sig_aldex2, taxa_info)
```

```{r}
#Clean up presentation
aldex2_results1 <- aldex2_da %>%
  rownames_to_column(var = "OTU")
  #filter(wi.eBH < 0.05) %>%
  #arrange(effect, wi.eBH) %>%
  #dplyr::select(OTU, diff.btw, diff.win, effect, wi.ep, wi.eBH)
aldex2_result2b <- left_join(aldex2_results1, taxa_info)
```


```{r}
sig_aldex2
write.csv(sig_aldex2, "res/sig_aldex2.csv")
write.csv(aldex2_result2b, "res/aldex2resultsAZM012m.csv")
```

14 taxa detected by Aldex2


###Corncob

```{r}
corn_da1 <- differentialTest(formula = ~ visit,
                            phi.formula = ~ 1,
                            formula_null = ~ 1,
                            phi.formula_null = ~ 1,
                            data = azm012pfg,
                            test = "Wald", boot = FALSE,fdr="BH",
                            fdr_cutoff = 0.05)

fdr_corncob <- corn_da1$significant_taxa
corn <- corn_da1$p_fdr
dim(data.frame(fdr_corncob))
```
```{r}
plot(corn_da1, total = TRUE, color = "trial_arm", B = 170)
```
Corncob  detected 22 DA taxa 

```{r}
fdr_corncob
write.csv(corn, "res/corncob_p_fdr.csv")
write.csv(fdr_corncob, "res/fdr_corncob.csv")
write.csv(corn_da1$p_fdr, "res/corncob-resultsAZM012m.csv")
```

#Write a code to pull estimate values for all models of each OTU else I will have to do it manually

```{r}
corndf1<-as.matrix(corn_da1[["all_models"]])

for (i in 1:171) {
  write.table( data.frame(corndf1[[i]][["coefficients"]]), 'res/corncob_estimatesAZM048_17122021.csv'  , append= T, sep=',' )
}

corndf1[[1]][["coefficients"]]
corndf1[[2]][["coefficients"]]
corndf1[[3]][["coefficients"]]
corndf1[[90]][["coefficients"]]
corndf1[[168]][["coefficients"]]
```


###MaAsLin 2

Normalisation = TSS, transformation= LOG, fixed effects= visit
```{r}
mas1 <- Maaslin2(
  input_data = data.frame(otu_table(azm012pfg)),
  input_metadata = data.frame(sample_data(azm012pfg)),
  output = "./MaAsLin2TSS_Log_visit",
  min_abundance = 0.0,
  min_prevalence = 0.0,
  normalization = "TSS",
  transform = "LOG",
  analysis_method = "LM",
  max_significance = 0.05,
  fixed_effects = "visit",
  correction = "BH",
  standardize = FALSE,
  cores = 1)
```

```{r}
mas1_res_df <- mas1$results

fdr_mas1 <- mas1_res_df %>%
    dplyr::filter(qval < 0.05)

dim(fdr_mas1)
```

28 DA found 
```{r}
fdr_mas1
write.csv(fdr_mas1, "./MaAsLin2TSS_Log_visit/fdr_mas1No_random_effects.csv")
write.csv(mas1_res_df, "./MaAsLin2TSS_Log_visit/mas1TSSNo_random_effectsAZM012.csv")
```

Normalisation = CLR, transformation= NONE, fixed effects= visit
data already clr-transformed hence normalisation option selected was "NONE"
```{r}
mas3 <- Maaslin2(
  input_data = data.frame(otu_table(azm012pfg_CLR)),
  input_metadata = data.frame(sample_data(azm012pfg_CLR)),
  output = "./MaAsLin2YAO_None_visit",
  min_abundance = 0.0,
  min_prevalence = 0.0,
  normalization = "NONE",
  transform = "NONE",
  analysis_method = "LM",
  max_significance = 0.05,
  fixed_effects = "visit",
  correction = "BH",
  standardize = FALSE,
  cores = 1)
```

```{r}
mas3_res_df <- mas3$results

fdr_mas3 <- mas3_res_df %>%
    dplyr::filter(qval < 0.05)

dim(fdr_mas3)

fdr_mas3
write.csv(fdr_mas3, "./MaAsLin2YAO_None_visit/fdr_mas3_NONE_None_No_random_effectsYAOCLR.csv")
write.csv(mas3_res_df, "./MaAsLin2YAO_None_visit/mas3CLR_YAO_No_random_effectsAZM012.csv")
```
31 DA detected

##Assessing overlap across approaches of MaAslin2


```{r}
Reduce(intersect, list(fdr_mas1$feature,fdr_mas3$feature ))   
```
Assessing the union taxa from all the MaAslin2 method
```{r}
Reduce(unique, list(fdr_mas1$feature,fdr_mas3$feature ))   
```

```{r}
da_venn <- venn.diagram(
  x = list(fdr_mas1$feature,fdr_mas3$feature),
  category.names = c("TSS_LOG_noRandom" , "CLR_NONE_noRandom"),
  filename = NULL,
  fill = c("#8DD3C7", "#FFFFB3"),
  margin = 0.1)

grid::grid.newpage()
grid::grid.draw(da_venn)   
```


ANCOM-II
Link https://github.com/FrederickHuangLin/ANCOM

```{r}
source("ancom_v2.1_reg.R")

```


```{r, preparing for Data preprocessing for ANCOM-II}
#Preparing otu_data for feature_table for Data preprocessing step
otu_data = as.matrix(azm012pfg@otu_table)
otu_data<-as.data.frame(otu_data)

#Preparing meta_data  for Data preprocessing step
meta_data<-as.matrix(sample_data(azm012pfg))
meta_data<-as.data.frame(meta_data)
write.csv(meta_data, "res/meta_data_paired_trial12mm.csv")
#edit im excel so the sample ids have a column heading "SampleID). I have to find a way to do this in R
meta_data_new<-read.csv("res/meta_data_paired_trial12mm.csv")
```


```{r, Data preprocessing for ANCOM-II}
# Step 1: Data preprocessing

feature_table = otu_data; sample_var = "X"; group_var = "visit"
out_cut = 0.05; zero_cut = 0.90; lib_cut = 0; neg_lb = TRUE

prepro = feature_table_pre_process(feature_table, meta_data_new, sample_var, group_var, 
                                   out_cut, zero_cut, lib_cut, neg_lb)

feature_table = prepro$feature_table # Preprocessed feature table
meta_data = prepro$meta_data # Preprocessed metadata
struc_zero = prepro$structure_zeros # Structural zero info
```



```{r, ANCOM-II}
# Step 2: ANCOM

main_var = "visit"; p_adj_method = "BH"; alpha = 0.05
adj_formula = NULL; rand_formula = NULL
control = lmeControl(maxIter = 100, msMaxIter = 100, opt = "optim")
t_start = Sys.time()
res = ANCOM(feature_table, meta_data, struc_zero, main_var, p_adj_method, 
            alpha, adj_formula, rand_formula, control = control)
t_end = Sys.time()
t_run = t_end - t_start # around 2mins

res
write_csv(res$out, "res/res_AZM012m_paired.csv")

write_csv(res$dat, "res/res_AZM012mpaired_clr.csv")
```



```{r}
ancom_res<-data.frame(res$out)
ancom_da<-ancom_res %>% 
  filter(detected_0.6==TRUE)
ancom_da$taxa_id #0
write.csv(ancom_da, "res/datrial12m.csv")

```



```{r, Plotting taxa}
# Step 3: Volcano Plot

# Number of taxa except structural zeros
n_taxa = ifelse(is.null(struc_zero), nrow(feature_table), sum(apply(struc_zero, 1, sum) == 0))
# Cutoff values for declaring differentially abundant taxa
cut_off = c(0.9 * (n_taxa -1), 0.8 * (n_taxa -1), 0.7 * (n_taxa -1), 0.6 * (n_taxa -1))
names(cut_off) = c("detected_0.9", "detected_0.8", "detected_0.7", "detected_0.6")

# Annotation data
dat_ann = data.frame(x = min(res$fig$data$x), y = cut_off["detected_0.7"], label = "W[0.7]")
```




```{r}
fig = res$fig + 
  geom_hline(yintercept = cut_off["detected_0.7"], linetype = "dashed") + 
  geom_text(data = dat_ann, aes(x = x, y = y, label = label), 
            size = 4, vjust = -0.5, hjust = 0, color = "orange", parse = TRUE)
fig 
```



```{r, Differentially abundant taxa detected by ANCOM-II}
ancom_res<-data.frame(res$out)
ancom_da<-ancom_res %>% 
  filter(detected_0.6==TRUE)
ancom_da$taxa_id #0
write.csv(ancom_da, "res/daAZM012m_allvisitspaired.csv")
```



```{r, Common to all nine, ten methods}
Reduce(intersect, list( fdr_deseq$ASVs, fdr_corncob, fdr_mas1$feature,fdr_mas3$feature, fdr_ancom1$Species, results.clrfg.WMWsig$taxon, results.TSSfg.WMWsig$taxon, results.vstfg.WMWsig$taxon, sig_aldex2$OTU, ancom_da$taxa_id))  
```











